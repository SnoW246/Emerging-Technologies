{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Problem Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *This Jupiter notebook captures and helps to visualize the learning process & outcome of simple [Machine Learning](https://en.wikipedia.org/wiki/Machine_learning) process using Fisher's Iris Data Set.* \n",
    "\n",
    "### Fisherâ€™s Iris Data Set\n",
    "\n",
    "The Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher).\n",
    "This data set was used as an example of [linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) in his 1936 paper *The use of multiple measurements in taxonomic problems*.\n",
    "\n",
    "#### *The data set consists of 50 samples from each of three species of Iris*\n",
    "* *Iris setosa*\n",
    "* *Iris virginica*\n",
    "* *Iris versicolor*\n",
    "\n",
    "#### *Four features were measured from each sample*\n",
    "* *The length & the width of the sepals , in centimetres.(cm)*\n",
    "* *The length & the width of the petals , in centimetres.(cm)*\n",
    "\n",
    "Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other. More information can be found [here](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "Original Python Problem sheet can be found [here](https://emerging-technologies.github.io/problems/tensorflow.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import neccessary libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from: https://github.com/salmanahmad4u/keras-iris/blob/master/iris_nn.py\n",
    "\n",
    "# Importing libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Load the iris dataset into a list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading Fisher's Iris Dataset\n",
    "# Data downloaded from: https://github.com/mwaskom/seaborn-data/blob/master/iris.csv\n",
    "iris = list(csv.reader(open(\"./Fishers-Iris-Data.csv\")))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Split the data into arrays*\n",
    "*Create a list that will contain all of the data. Then populate arrays using sub-elements of that list, with use of [slicing](https://www.pythoncentral.io/how-to-slice-listsarrays-and-tuples-in-python/) method in python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The inputs are four floats: sepal length, sepal width, petal length, petal width.\n",
    "inputs  = np.array(iris)[:,:4].astype(np.float)\n",
    "\n",
    "# Outputs are initially individual strings: setosa, versicolor or virginica.\n",
    "outputs = np.array(iris)[:,4]\n",
    "# Convert the output strings to ints.\n",
    "outputs_vals, outputs_ints = np.unique(outputs, return_inverse=True)\n",
    "# Encode the category integers as binary categorical vairables.\n",
    "outputs_cats = kr.utils.to_categorical(outputs_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Split the data into train & test subsets*\n",
    "Spritting the data will allow for model training with the training subset. After model gets trained, testing subset can be used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the input and output data sets into training and test subsets.\n",
    "inds = np.random.permutation(len(inputs))\n",
    "train_inds, test_inds = np.array_split(inds, 2)\n",
    "\n",
    "inputs_train, outputs_train = inputs[train_inds], outputs_cats[train_inds]\n",
    "inputs_test,  outputs_test  = inputs[test_inds],  outputs_cats[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create a [neural network](https://www.tensorflow.org/versions/r0.12/tutorials/). Add layers & nodes to it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a neural network.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add an initial layer with 4 input nodes, and a hidden layer with 16 nodes.\n",
    "model.add(kr.layers.Dense(16, input_shape=(4,)))\n",
    "# Apply the sigmoid activation function to that layer.\n",
    "model.add(kr.layers.Activation(\"sigmoid\"))\n",
    "# Add another layer, connected to the layer with 16 nodes, containing three output nodes.\n",
    "model.add(kr.layers.Dense(3))\n",
    "# Use the softmax activation function there.\n",
    "model.add(kr.layers.Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Visual sample of neural network *\n",
    "![Neural Network](NeuralNetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Model Configuration for training*\n",
    "\n",
    "Compiling the data using [Adam optimizer](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "# Uses the adam optimizer and categorical cross entropy as the loss function.\n",
    "# Add in some extra metrics - accuracy being the only one.\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Fitting & evaluating the model with data*\n",
    "Training the model with epoch of 100. Evaluating the test data & outputting results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s - loss: 1.1619 - acc: 0.3333     \n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s - loss: 1.0675 - acc: 0.4267     \n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s - loss: 0.9849 - acc: 0.6533        \n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s - loss: 0.9106 - acc: 0.8133     \n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s - loss: 0.8446 - acc: 0.8400     \n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s - loss: 0.7839 - acc: 0.8533     \n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s - loss: 0.7348 - acc: 0.8667     \n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s - loss: 0.6924 - acc: 0.9200     \n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s - loss: 0.6525 - acc: 0.8000     \n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s - loss: 0.6195 - acc: 0.8933     \n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s - loss: 0.5902 - acc: 0.9067     \n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s - loss: 0.5630 - acc: 0.9600     \n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s - loss: 0.5439 - acc: 0.8667     \n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s - loss: 0.5216 - acc: 0.9333     \n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s - loss: 0.5040 - acc: 0.9467     \n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s - loss: 0.4897 - acc: 0.9067     \n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s - loss: 0.4746 - acc: 0.9600     \n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s - loss: 0.4644 - acc: 0.9733     \n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s - loss: 0.4526 - acc: 0.9733     \n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s - loss: 0.4417 - acc: 0.9467     \n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s - loss: 0.4321 - acc: 0.9467     \n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s - loss: 0.4234 - acc: 0.9467     \n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s - loss: 0.4143 - acc: 0.9467     \n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s - loss: 0.4084 - acc: 0.9600     \n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s - loss: 0.3997 - acc: 0.9600     \n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s - loss: 0.3936 - acc: 0.9333     \n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s - loss: 0.3847 - acc: 0.9467     \n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s - loss: 0.3780 - acc: 0.9467     \n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s - loss: 0.3714 - acc: 0.9600     \n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s - loss: 0.3690 - acc: 0.9333     \n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s - loss: 0.3581 - acc: 0.9733     \n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s - loss: 0.3511 - acc: 0.9600     \n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s - loss: 0.3468 - acc: 0.9467     \n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s - loss: 0.3398 - acc: 0.9600     \n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s - loss: 0.3341 - acc: 0.9600     \n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s - loss: 0.3290 - acc: 0.9600     \n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s - loss: 0.3200 - acc: 0.9600     \n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s - loss: 0.3170 - acc: 0.9333     \n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s - loss: 0.3091 - acc: 0.9733     \n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s - loss: 0.3073 - acc: 0.9600     \n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s - loss: 0.2958 - acc: 0.9867     \n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s - loss: 0.2925 - acc: 0.9733         \n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s - loss: 0.2874 - acc: 0.9733         \n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s - loss: 0.2815 - acc: 0.9733     \n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s - loss: 0.2788 - acc: 0.9733     \n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s - loss: 0.2734 - acc: 0.9600     \n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s - loss: 0.2671 - acc: 0.9867     \n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s - loss: 0.2645 - acc: 0.9733     \n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s - loss: 0.2594 - acc: 0.9867     \n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s - loss: 0.2542 - acc: 0.9600     \n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s - loss: 0.2489 - acc: 0.9600     \n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s - loss: 0.2458 - acc: 0.9867     \n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s - loss: 0.2409 - acc: 0.9467     \n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s - loss: 0.2383 - acc: 0.9733     \n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s - loss: 0.2370 - acc: 0.9600     \n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s - loss: 0.2320 - acc: 0.9600     \n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s - loss: 0.2271 - acc: 0.9733     \n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s - loss: 0.2260 - acc: 0.9733     \n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s - loss: 0.2198 - acc: 0.9733     \n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s - loss: 0.2149 - acc: 0.9600     \n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s - loss: 0.2153 - acc: 0.9867     \n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s - loss: 0.2108 - acc: 0.9733     \n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s - loss: 0.2082 - acc: 0.9600     \n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s - loss: 0.2030 - acc: 0.9733     \n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s - loss: 0.2015 - acc: 0.9733     \n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s - loss: 0.1994 - acc: 0.9733     \n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s - loss: 0.1947 - acc: 0.9733     \n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s - loss: 0.1914 - acc: 0.9733     \n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s - loss: 0.1909 - acc: 0.9600     \n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s - loss: 0.1850 - acc: 0.9600     \n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s - loss: 0.1864 - acc: 0.9600     \n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s - loss: 0.1812 - acc: 0.9733     \n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s - loss: 0.1781 - acc: 0.9733     \n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s - loss: 0.1763 - acc: 0.9733     \n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s - loss: 0.1739 - acc: 0.9733     \n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s - loss: 0.1718 - acc: 0.9733     \n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s - loss: 0.1694 - acc: 0.9733     \n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s - loss: 0.1673 - acc: 0.9867         \n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s - loss: 0.1710 - acc: 0.9600     \n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s - loss: 0.1625 - acc: 0.9600     \n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s - loss: 0.1640 - acc: 0.9600     \n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s - loss: 0.1629 - acc: 0.9867     \n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s - loss: 0.1567 - acc: 0.9867     \n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s - loss: 0.1537 - acc: 0.9867     \n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s - loss: 0.1544 - acc: 0.9733     \n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s - loss: 0.1552 - acc: 0.9600     \n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s - loss: 0.1515 - acc: 0.9733     \n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s - loss: 0.1478 - acc: 0.9733     \n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s - loss: 0.1460 - acc: 0.9867     \n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s - loss: 0.1427 - acc: 0.9733     \n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s - loss: 0.1420 - acc: 0.9867     \n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s - loss: 0.1399 - acc: 0.9867     \n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s - loss: 0.1412 - acc: 0.9467     \n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s - loss: 0.1400 - acc: 0.9733     \n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s - loss: 0.1416 - acc: 0.9733     \n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s - loss: 0.1337 - acc: 0.9600     \n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s - loss: 0.1350 - acc: 0.9733     \n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s - loss: 0.1315 - acc: 0.9733     \n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s - loss: 0.1312 - acc: 0.9733     \n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s - loss: 0.1344 - acc: 0.9600     \n",
      "32/75 [===========>..................] - ETA: 0s\n",
      "\n",
      "Loss: 0.1272\tAccuracy: 0.9867\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using our training data.\n",
    "model.fit(inputs_train, outputs_train, epochs=100, batch_size=1, verbose=1)\n",
    "\n",
    "# Evaluate the model using the test data set.\n",
    "loss, accuracy = model.evaluate(inputs_test, outputs_test, verbose=1)\n",
    "\n",
    "# Output the accuracy of the model.\n",
    "print(\"\\n\\nLoss: %6.4f\\tAccuracy: %6.4f\" % (loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Accuracy is between 97%-98%. Based on this output, model should be extremely accurate.\n",
    "### *Prediction of data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [1 0 0]\tEstimated: [1 0 0]\n",
      "That means it's a setosa\n"
     ]
    }
   ],
   "source": [
    "# Predict the class of a single flower.\n",
    "prediction = np.around(model.predict(np.expand_dims(inputs_test[0], axis=0))).astype(np.int)[0]\n",
    "print(\"Actual: %s\\tEstimated: %s\" % (outputs_test[0].astype(np.int), prediction))\n",
    "print(\"That means it's a %s\" % outputs_vals[prediction.astype(np.bool)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piece of data was randomly picked and checked against. Purpose of this is to see if model can predict data accurately.\n",
    "Results turn out to be really accurate, based on accuracy level of the model outputed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Save the model for later use*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model to a file for later use.\n",
    "model.save(\"iris_nn.h5\")\n",
    "# Load the model again with: model = load_model(\"iris_nn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
